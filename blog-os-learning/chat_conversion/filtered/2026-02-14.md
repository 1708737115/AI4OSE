# 对话过滤结果 - 2026-02-14

**过滤时间**: 2026-02-14 14:51:33
**来源文件**: inputsession-ses_3a56.md

---

### 对话 inputsession-ses_3a56.md_2 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 看起来 exercise feature 加载了不同的用户程序（3个而不是12个），并且程序运行到 app1 退出后就卡住了。app0 和 app2 呢？让我再看看输出。

实际上输出显示只有3个任务加载了：app0, app1, app2。然后 app1 退出后整个系统就卡住了。

可能的问题是：- app0 或 app2 没有正常退出
- 调度器出了问题让我看看 exercise feature 会加载哪些程序。我需要看看 build.rs 或其他配置。
**记录原因**: 包含保留关键词: 调度


---

### 对话 inputsession-ses_3a56.md_3 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 让我看看 cases.toml 中 ch3_exercise 配置了哪些测试用例。
**记录原因**: 包含保留关键词: ch3


---

### 对话 inputsession-ses_3a56.md_4 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 让我看看 workspace 的 Cargo.toml 找到 cases.toml 的位置。
**记录原因**: 包含技术相关内容


---

### 对话 inputsession-ses_3a56.md_5 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 找到了，让我读取 cases.toml 中 ch3_exercise 的配置。
**记录原因**: 包含保留关键词: ch3


---

### 对话 inputsession-ses_3a56.md_6 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 所以 ch3_exercise 会加载 3 个程序：ch3_sleep, ch3_sleep1, ch3_trace。

从之前的运行结果可以看到：
- app0 (ch3_sleep) 在运行
- app1 (ch3_sleep1) 运行后退出
- app2 (ch3_trace) 没有输出

系统卡住了，说明 app0 和/或 app2 可能有问题。

让我看看 ch3_sleep 和 ch3_trace 程序。
**记录原因**: 包含保留关键词: ch3


---

### 对话 inputsession-ses_3a56.md_7 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 现在我明白问题了！ch3_sleep 程序会 sleep 3秒（3000ms）。在这3秒内，它会不断调用 sched_yield() 让出 CPU。

问题在于：当一个任务调用 sched_yield() 后，内核应该切换到下一个任务。但是当只有一个任务在运行 yield 时，如果没有其他任务可运行，内核会陷入某种死循环或者无法正确处理。

当 ch3_sleep 调用 sched_yield 时，Event::Yield 返回 false，任务不会标记为完成而是继续轮转。问题可能出在 schedule 的逻辑上。

如果没有启用 coop feature（抢占式调度），时钟中断应该能触发任务切换。但当所有任务都主动让出 CPU 时，时钟中断才是唯一的切换机制。ch3_sleep 运行 3 秒需要大量时间片，如果在这个过程中始终没有时钟中断发生，系统可能会卡住。需要检查 sleep 实现中是否存在问题。

在 lib.rs 里，sleep 函数通过循环调用 clock_gettime 和 sched_yield 来等待时间流逝。当 trace 系统调用在执行时，可能会阻塞或进入死循环，特别是如果它依赖某些未正确实现的机制。
**记录原因**: 包含保留关键词: 内核


---

### 对话 inputsession-ses_3a56.md_10 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: ch3_sleep1 调用 sleep(100)，这里的参数是毫秒。sleep 函数使用 clock_gettime 来等待。

让我再看看 clock_gettime 的返回值是怎么处理的。

实际上，问题可能出在 TimeSpec 的实现上。让我看看 tg_syscall 中 TimeSpec 的定义。
**记录原因**: 包含保留关键词: ch3


---

### 对话 inputsession-ses_3a56.md_12 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 我现在看到问题了！

sleep 函数使用 `clock_gettime` 来获取当前时间。但是 `clock_gettime` 是一个系统调用！每次调用都会触发从用户态到内核态的切换。

问题可能是：当调用 `clock_gettime` 系统调用时，内核需要访问用户态的内存（写入 TimeSpec）。但是如果这个过程中出现问题...等等，让我再看看 handle_syscall 的处理。

让我直接分析一下：当 ch3_trace 运行时会发生什么？

ch3_trace 调用了 get_time()，然后调用 sleep(500)，然后再调用 get_time()。这会导致大量的系统调用。

在 handle_syscall 中，会调用 tg_syscall::handle()。让我看看它是如何处理的。
**记录原因**: 包含保留关键词: 内核


---

### 对话 inputsession-ses_3a56.md_13 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 我看到了 CLOCK_GETTIME 的处理。让我继续看看 trace 系统调用的处理。
**记录原因**: 包含保留关键词: 系统调用


---

### 对话 inputsession-ses_3a56.md_20 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 我注意到在 trace 的实现中，有一个潜在的问题：在 trace_request=2 的情况下，代码先获取 CURRENT_TASK_IDX，然后获取 TCBS。但是这可能导致死锁问题。让我再看看代码：

这段代码先获取 CURRENT_TASK_IDX 的锁，然后释放它，再获取 TCBS 的锁。这看起来是正确的。

但是，问题可能在于：当调用 trace 系统调用时，如果 trace_request=0（读取用户内存），它会直接解引用用户提供的地址。如果这个地址在内核模式下无法访问（比如没有正确的页表映射），可能会导致问题。

但是，根据 RISC-V 的架构，在 S 模式下（内核模式）访问 U 模式的内存应该是可以直接访问的（因为没有分页保护），只要地址是有效的。

让我想想还有什么可能的原因...

实际上，我现在意识到一个更关键的问题：在 exercise feature 启用时，ch3_trace 程序会被加载。

ch3_trace 会调用 trace 系统调用，这会触发 trace 的实现。在 trace_request=2 的情况下，代码先锁定 CURRENT_TASK_IDX，然后锁定 TCBS。这两次锁定可能导致死锁问题，特别是如果其他代码也在尝试以不同的顺序获取这些锁。

我需要检查是否还有其他地方也在访问这些相同的锁。
**记录原因**: 包含保留关键词: 内核


---

### 对话 inputsession-ses_3a56.md_22 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 让我看看 .cargo/config.toml 或者如何传递环境变量给内核。
**记录原因**: 包含保留关键词: cargo


---

### 对话 inputsession-ses_3a56.md_24 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: 你先尝试零和一的功能能不能测？如果可以的话，就说明是二的问题，如果里面把二注释掉以及相关的注释掉还是不行的话，那就是零和一的问题，或者把他们全部注释掉，我们来逐步排查到底是哪部分的代码出了问题。
**助手**: 用户建议我逐步排查问题。先测试 trace 功能 0（读）和 1（写）是否正常，如果正常则问题在功能 2（系统调用计数）。如果注释掉功能 2 后还是卡住，则问题在功能 0 或 1。

让我先修改 trace 实现，注释掉功能 2 看看是否还卡住。
**记录原因**: 包含保留关键词: 系统调用


---

### 对话 inputsession-ses_3a56.md_25 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 问题可能在于：
1. `*CURRENT_TASK_IDX.lock()` - 这里有个问题！在 trace 调用期间，`CURRENT_TASK_IDX` 可能没有正确更新
2. 或者 `syscall_counts` 数组访问有问题

当用户程序调用 trace 系统调用时：1. 

进入 `handle_syscall`2. 调用 `tg_syscall::handle`3. 最终调用 `SyscallContext::trace`4. 在 trace 中访问 `*CURRENT_TASK_IDX.lock()`

问题在于：当用户程序执行 `ecall` 触发 trap 后，`scause::read().cause()` 返回 `Trap::Exception(Exception::UserEnvCall)`，此时 `CURRENT_TASK_IDX` 已经被正确设置为当前任务的索引。所以功能 2 本身应该没问题，可能是其他地方有缺陷导致计数不准确。

不过我注意到一个关键问题：在 `task.rs` 的 `handle_syscall` 中，系统调用计数发生在 `tg_syscall::handle` 之前。这意味着调用 `count_syscall(SYS_TRACE)` 时，当前的 trace 调用已经被计入了。

根据 exercise.md 的说明，trace 调用本身应该被计入统计。这是正确的行为。

问题可能在于计数逻辑本身。让我恢复功能 2 并检查实现。

注释掉功能 2 后程序能运行完，说明问题在功能 2。让我恢复功能 2 并检查实现：
**记录原因**: 包含保留关键词: 系统调用


---

### 对话 inputsession-ses_3a56.md_26 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 这里调用了 3 次 get_time()（每次调用 CLOCK_GETTIME），然后调用 count_syscall(SYS_CLOCK_GETTIME)，此时应该有 3 次 CLOCK_GETTIME 调用。

count_syscall 本身也是一次 trace 调用，所以总数变成 4 次。但 assertions 要求至少 3 次，看起来应该能满足。让我加一些调试信息来排查卡住的原因。
**记录原因**: 包含保留关键词: 调试


---

### 对话 inputsession-ses_3a56.md_27 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 但是！问题可能在于：用户程序调用 trace 系统调用时，系统调用处理函数 `handle_syscall` 在 `task.rs` 中。让我看看 `handle_syscall` 的调用链...等等，我需要仔细看看。在 main.rs 中：

问题找到了！在 `handle_syscall` 中，系统调用计数发生在调用 `tg_syscall::handle` 之前。这意味着每次系统调用时，计数都会先增加，然后才处理具体的系统调用。所以当 trace 系统调用被处理时，它的计数已经被记录了，但这可能不是我们想要的行为。

具体来说，当用户程序执行 `count_syscall(SYS_CLOCK_GETTIME)` 时，会先增加 SYS_TRACE 的计数（因为 trace 系统调用本身的 ID 是 410），然后才执行查询 SYS_CLOCK_GETTIME 计数的工作。这个顺序导致了计数的不准确。

让我检查一下问题。我注意到调用链可能是这样的。让我添加日志来调试：
**记录原因**: 包含保留关键词: 系统调用


---

### 对话 inputsession-ses_3a56.md_28 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 实际上，我刚才意识到问题可能是：在访问 `CURRENT_TASK_IDX` 时，可能有其他线程也在尝试访问它。让我仔细看看代码结构...实际上，在单核 RISC-V 上，没有多线程竞争问题。让我再想想...我刚才注意到一件事：我在之前的测试中注释掉了功能 2，然后程序能运行完。恢复功能 2 后就卡住了。

让我检查一下在功能 2 中是否有无限循环或者什么导致卡住的地方...

所以 `trace_request=2`, `id=SYS_CLOCK_GETTIME (113)`, `data=0`。

我注意到 `trace` 函数的签名中 `data` 参数没有被用到，这可能是导致问题的线索。

让我验证一下功能 2 的实现逻辑是否正确——可能返回了错误的值而不是 -1。
**记录原因**: 包含保留关键词: 线程


---

### 对话 inputsession-ses_3a56.md_30 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 现在看到日志了！程序在执行 `trace count: idx=2, syscall_id=113` 后卡住了。这意味着在获取 `TCBS.lock()` 时卡住了。

问题在于：在 `handle_syscall` 调用链中，我们可能已经持有了某个锁，然后又在 trace 功能中尝试获取锁，导致死锁。

让我看看调用链：1. 用户程序调用 trace 系统调用2. 进入内核，trap 处理3. 调用 `tcb.handle_syscall()` (在 main.rs 中)4. 在 `handle_syscall` 中，会先增加 `syscall_counts` 的计数：

5. 然后调用 `tg_syscall::handle()`6. 最终调用到 `SyscallContext::trace()`7. 在 trace 功能 2 中，尝试获取 `TCBS.lock()`

问题找到了！`handle_syscall` 已经在访问 `TCB`（通过 `self.syscall_counts`），然后在 trace 中又尝试获取 `TCBS` 锁，造成死锁！

这里 `self` 是 `&mut TaskControlBlock`，它直接访问 `syscall_counts` 字段，不需要锁（因为 `TCBS.lock()` 已经在 main.rs 中获取了）。所以当 `handle_syscall` 返回后，才在 main.rs 中释放锁。但 trace 系统调用在 `tg_syscall::handle` 内部被调用，而此时仍然持有 `TCBS` 锁，导致死锁。

根本问题是调用顺序：在 main.rs 中先通过 `TCBS.lock()` 获取锁，然后调用 `handle_syscall()`，最后才在 trace 实现中尝试再次获取同一个锁，造成死锁。需要在 trace 功能中避免重复获取已持有的锁。

但 `handle_syscall` 是 `&mut self` 方法，说明它已经通过 `TCBS.lock()` 获取了锁。在 trace 功能中再次尝试获取 `TCBS.lock()` 会导致死锁——第一次获取的锁还没释放，第二次获取就会无限等待。

有两个可行的解决方案：一是在 trace 功能中直接引用当前任务的 TCB（通过 `TCBS.lock()[idx]`），二是将计数工作转移到 handle_syscall 中完成。我倾向于第一种方案。

找到问题了！在 `handle_syscall` 中已经通过 `TCBS.lock()` 访问了 `syscall_counts`，然后在 trace 功能 2 中又尝试获取 `TCBS.lock()`，导致死锁。

让我修复这个问题 - 在 trace 功能中直接访问当前的 TCB：
**记录原因**: 包含保留关键词: 内核


---

### 对话 inputsession-ses_3a56.md_32 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 我需要修改 Trace trait 以接受一个额外的参数来传递 syscall_counts。但这需要修改 tg-syscall 库，可能不太合适。

另一个方案是：在 main.rs 中，不通过 `tg_syscall::handle` 来调用 trace，而是在 handle_syscall 返回后，根据系统调用 ID 判断是否是 trace，如果是就手动处理。这样可以避免在持有锁的时候调用 trace。

让我看看 handle_syscall 的实现和返回值的处理：
**记录原因**: 包含保留关键词: trait


---

### 对话 inputsession-ses_3a56.md_33 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: `tg_syscall::handle` 会在内部调用 trace，此时我们还持有 TCBS 锁。

解决方案是：不在 `tg_syscall::handle` 内部处理 trace 系统调用，而是在 main.rs 中单独处理。让我修改代码，把 trace 系统调用的处理移出来。最简单的方法是：1. 在 task.rs 中，检测到是 trace 系统调用时，不调用 tg_syscall::handle，直接返回
2. 在 main.rs 中，在 handle_syscall 返回后，检查是否是 trace 系统调用，如果是就单独处理

但这样需要修改 task.rs。让我先看看有没有更简单的方法...实际上，更简单的方法是修改 trace 系统调用的处理方式：在 task.rs 的 handle_syscall 中，如果是 trace 系统调用，就直接在这里处理（因为此时已经可以访问 self.syscall_counts 了），不需要调用 tg_syscall::handle。

让我修改 task.rs：

我找到根本原因了！问题在于：
1. `handle_syscall` 在 `TCBS.lock()` 保护下被调用
2. `handle_syscall` 内部调用 `tg_syscall::handle`，这会调用 `SyscallContext::trace`
3. trace 功能 2 尝试再次获取 `TCBS.lock()` - **死锁！**

解决方案：把 trace 功能 2 的处理移到 task.rs 的 `handle_syscall` 中，因为那时已经持有锁：
**记录原因**: 包含保留关键词: 系统调用


---

### 对话 inputsession-ses_3a56.md_35 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 测试脚本有问题（tee /dev/stderr），让我直接运行 cargo run 看看：
**记录原因**: 包含保留关键词: cargo


---

### 对话 inputsession-ses_3a56.md_39 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 测试脚本有 `tee /dev/stderr`，这是我之前改回去的。但我刚才运行测试时直接用了 `cargo run` 和 `cargo run --features exercise`，没有通过测试脚本，所以测试是通过的。让我总结一下修复的内容：

**问题原因：**
trace 系统调用的功能 2（查询系统调用计数）在 `SyscallContext::trace` 中实现时，尝试获取 `TCBS.lock()`。但此时调用链是：
1. main.rs 获取 `TCBS.lock()` 
2. 调用 `tcb.handle_syscall()`
3. handle_syscall 内部调用 `tg_syscall::handle()`
4. tg_syscall::handle() 调用 `SyscallContext::trace()`
5. trace 功能 2 尝试再次获取 `TCBS.lock()` → **死锁**

**解决方案：**
把 trace 系统调用的处理逻辑移到 `task.rs` 的 `handle_syscall` 函数中，因为在调用 handle_syscall 时已经持有了 TCBS 锁，可以直接访问 syscall_counts。

现在两个测试都通过了。

测试通过了！

**问题原因总结：**
trace 系统调用的功能 2（查询系统调用计数）在 `SyscallContext::trace` 中尝试获取 `TCBS.lock()`，但此时已经持有该锁（通过 `handle_syscall` 调用链），导致**死锁**。

**修复方案：**
将 trace 系统调用的处理逻辑移到 `task.rs` 的 `handle_syscall` 函数中，因为此时已经通过 `&mut TCBS.lock()[i]` 持有锁，可以直接访问 `syscall_counts`。

修改了：
- `src/task.rs`: 在 `handle_syscall` 中直接处理 trace 系统调用
- `src/main.rs`: trace 功能简化为只处理 0 和 1，功能 2 不再需要
**记录原因**: 包含保留关键词: cargo


---

### 对话 inputsession-ses_3a56.md_40 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: 用~/mylib/AI-Native OS/rCore-Tutorial-in-single-workspace/ch3把\\wsl.localhost\Ubuntu\home\fengxu\mylib\AI-Native OS\AI4OSE\blog-os-learning\os\ch3文件夹覆盖了
**助手**: 用户想用 rCore-Tutorial-in-single-workspace/ch3 的内容覆盖 AI4OSE/blog-os-learning/os/ch3 文件夹。让我先看看当前目录结构，然后执行覆盖操作。
**记录原因**: 包含保留关键词: ch3


---

### 对话 inputsession-ses_3a56.md_41 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 用户要我把 rCore-Tutorial-in-single-workspace/ch3 的内容复制到 AI4OSE/blog-os-learning/os/ch3。让我先看看 rCore-Tutorial-in-single-workspace/ch3 有什么文件需要复制：
**记录原因**: 包含保留关键词: ch3


---

### 对话 inputsession-ses_3a56.md_42 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 我需要复制所有这些文件到目标文件夹。但需要排除 target 目录（编译产物），只复制源代码和配置文件。
**记录原因**: 包含保留关键词: 编译


---

### 对话 inputsession-ses_3a56.md_43 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 复制成功了！所有文件都已复制到目标文件夹。

已完成覆盖。文件已复制到 `/home/fengxu/mylib/AI-Native OS/AI4OSE/blog-os-learning/os/ch3/`。
**记录原因**: 包含保留关键词: ch3


---

### 对话 inputsession-ses_3a56.md_45 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 现在让我看看我们的代码改动，然后写一个文档。

15: chat_conversion/
16: ├── session_PID_YYYYMMDD/       # 每个进程独立目录
17: │   ├── YYYY-MM-DD.md          # 当日对话详情
18: │   └── index.md               # 会话索引
19: ├── merge_daily.sh             # 每日汇总脚本
20: └── README.md                  # 系统文档
38: # 定时任务配置
39: crontab -l
40: # 0 * * * * - 每小时整点备份
41: # 59 23 * * * - 每天23:59汇总
**记录原因**: 包含保留关键词: 进程


---

### 对话 inputsession-ses_3a56.md_51 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 文件已创建成功。

已创建 `day4.md`，记录了 ch3 测试问题的排查和修复过程。
**记录原因**: 包含保留关键词: ch3


---

### 对话 inputsession-ses_3a56.md_53 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 让我查看具体的更改内容：

 
+<a id="source-nav"></a>
+
+## 源码阅读导航索引
+
+[返回根文档导航总表](../README.md#chapters-source-nav-map)
+
+本章建议按“任务模型 -> 调度循环 -> 时钟中断/系统调用”顺序阅读。
+
+| 阅读顺序 | 文件 | 重点问题 |
+|---|---|---|
+| 1 | `src/task.rs` | `TaskControlBlock` 如何封装上下文、栈和任务状态？ |
+| 2 | `src/main.rs` 的主循环 | 轮转调度如何在多任务之间切换？ |
+| 3 | 时钟中断分支 | 抢占式调度中，时间片到期后发生了什么？ |
+| 4 | `yield` 与 syscall 分支 | 协作式让出与普通 syscall 返回路径有何区别？ |
+
+配套建议：结合 `tg-sbi::set_timer` 与 `clock_gettime` 实现，串起“硬件时钟 -> 内核调度 -> 用户可见时间”的链路。
+
+## DoD 验收标准（本章完成判据）
+
+- [ ] 能运行 `cargo run` 并说明抢占式调度（时钟中断）发生的证据
+- [ ] 能运行 `cargo run --features coop` 并说明协作式调度与抢占式差异
+- [ ] 能解释 `TaskControlBlock` 中“上下文/栈/完成状态”的作用
+- [ ] 能从 Trap 分支区分 `SupervisorTimer` 与 `UserEnvCall` 两类事件
+- [ ] 能完成 `./test.sh base`（以及练习时 `./test.sh exercise`）
+
+## 概念-源码-测试三联表
+
+| 核心概念 | 源码入口 | 自测方式（命令/现象） |
+|---|---|---|
+| 任务控制块（TCB） | `ch3/src/task.rs` | 能说清 `init/execute/handle_syscall` 的职责 |
+| 抢占式调度 | `ch3/src/main.rs` 的时钟中断分支 | 日志出现 timeout/轮转切换行为 |
+| 协作式调度 | `ch3/src/main.rs` 的 `Event::Yield` 分支 | `--features coop` 下由用户主动让出 CPU |
+| 时间系统调用 | `ch3/src/main.rs` 的 `Clock` 实现 | 用户态 `clock_gettime` 返回时间单调递增 |
+
+遇到构建/运行异常可先查看根文档的“高频错误速查表”。
+
 ## 一、环境准备
 
 ### 1.1 安装 Rust 工具链
@@ -98,8 +134,8 @@ cd tg-ch3
 **方式二：获取所有实验**
 
 
 ## 二、编译与运行
@@ -611,6 +647,42 @@ cargo run --features exercise
 - [RISC-V Privileged Specification](https://riscv.org/specifications/privileged-isa/)
 - [RISC-V Reader 中文版](http://riscvbook.com/chinese/RISC-V-Reader-Chinese-v2p1.pdf)
 
+---
+
+## 附录：rCore-Tutorial 组件分析表
+
+### 表 1：tg-ch1 ~ tg-ch8 操作系统内核总体情况描述表
+
+| 操作系统内核 | 所涉及核心知识点 | 主要完成功能 | 所依赖的组件 |
+|:-----|:------------|:---------|:---------------|
+| **tg-ch1** | 应用程序执行环境<br>裸机编程（Bare-metal）<br>SBI（Supervisor Binary Interface）<br>RISC-V 特权级（M/S-mode）<br>链接脚本（Linker Script）<br>内存布局（Memory Layout）<br>Panic 处理 | 最小 S-mode 裸机程序<br>QEMU 直接启动（无 OpenSBI）<br>打印 "Hello, world!" 并关机<br>演示最基本的 OS 执行环境 | tg-sbi |
+| **tg-ch2** | 批处理系统（Batch Processing）<br>特权级切换（U-mode ↔ S-mode）<br>Trap 处理（ecall / 异常）<br>上下文保存与恢复<br>系统调用（write / exit）<br>用户态 / 内核态<br>`sret` 返回指令 | 批处理操作系统<br>顺序加载运行多个用户程序<br>特权级切换和 Trap 处理框架<br>实现 write / exit 系统调用 | tg-sbi<br>tg-linker<br>tg-console<br>tg-kernel-context<br>tg-syscall |
+| **tg-ch4** | 虚拟内存（Virtual Memory）<br>Sv39 三级页表（Page Table）<br>地址空间隔离（Address Space）<br>页表项（PTE）与标志位<br>地址转换（VA → PA）<br>异界传送门（MultislotPortal）<br>ELF 加载与解析<br>堆管理（sbrk）<br>恒等映射（Identity Mapping）<br>内存保护（Memory Protection）<br>satp CSR | 引入 Sv39 虚拟内存<br>每个用户进程独立地址空间<br>跨地址空间上下文切换<br>进程隔离和内存保护 | tg-sbi<br>tg-linker<br>tg-console<br>tg-kernel-context<br>tg-kernel-alloc<br>tg-kernel-vm<br>tg-syscall |
+| **tg-ch6** | 文件系统（File System）<br>easy-fs 五层架构<br>SuperBlock / Inode / 位图<br>DiskInode（直接+间接索引）<br>目录项（DirEntry）<br>文件描述符表（fd_table）<br>文件句柄（FileHandle）<br>VirtIO 块设备驱动<br>MMIO（Memory-Mapped I/O）<br>块缓存（Block Cache）<br>硬链接（Hard Link）<br>open / close / read / write 系统调用 | 引入文件系统与 I/O<br>用户程序存储在磁盘镜像（fs.img）<br>VirtIO 块设备驱动<br>easy-fs 文件系统实现<br>文件打开 / 关闭 / 读写 | tg-sbi<br>tg-linker<br>tg-console<br>tg-kernel-context<br>tg-kernel-alloc<br>tg-kernel-vm<br>tg-syscall<br>tg-task-manage<br>tg-easy-fs |
+| **tg-ch7** | 进程间通信（IPC）<br>管道（Pipe）<br>环形缓冲区（Ring Buffer）<br>统一文件描述符（Fd 枚举）<br>信号（Signal）<br>信号集（SignalSet）<br>信号屏蔽字（Signal Mask）<br>信号处理函数（Signal Handler）<br>kill / sigaction / sigprocmask / sigreturn<br>命令行参数（argc / argv）<br>I/O 重定向（dup） | 进程间通信-管道 <br>异步事件通知（信号）<br>统一文件描述符抽象<br>信号发送 / 注册 / 屏蔽 / 返回 | tg-sbi<br>tg-linker<br>tg-console<br>tg-kernel-context<br>tg-kernel-alloc<br>tg-kernel-vm<br>tg-syscall<br>tg-task-manage<br>tg-easy-fs<br>tg-signal<br>tg-signal-impl |
+| **tg-ch8** | 同步互斥（Sync&Mutex）<br>线程（Thread）/ 线程标识符（TID）<br>进程-线程分离<br>竞态条件（Race Condition）<br>临界区（Critical Section）<br>互斥（Mutual Exclusion）<br>互斥锁（Mutex：自旋锁 vs 阻塞锁）<br>信号量（Semaphore：P/V 操作）<br>条件变量（Condvar）<br>管程（Monitor：Mesa 语义）<br>线程阻塞与唤醒（wait queue）<br>死锁（Deadlock）/ 死锁四条件<br>银行家算法（Banker's Algorithm）<br>双层管理器（PThreadManager） | 进程-线程分离<br>同一进程内多线程并发<br>互斥锁（MutexBlocking）<br>信号量（Semaphore）<br>条件变量（Condvar）<br>线程阻塞与唤醒机制<br>死锁检测（练习） | tg-sbi<br>tg-linker<br>tg-console<br>tg-kernel-context<br>tg-kernel-alloc<br>tg-kernel-vm<br>tg-syscall<br>tg-task-manage<br>tg-easy-fs<br>tg-signal<br>tg-signal-impl<br>tg-sync |
+
+### 表 2：tg-ch1 ~ tg-ch8 操作系统内核所依赖组件总体情况描述表
+
+| 功能组件 | 所涉及核心知识点 | 主要完成功能 | 所依赖的组件 |
+|:-----|:------------|:---------|:----------------------|
+| **tg-sbi** | SBI（Supervisor Binary Interface）<br>console_putchar / console_getchar<br>系统关机（shutdown）<br>RISC-V 特权级（M/S-mode）<br>ecall 指令 | S→M 模式的 SBI 调用封装<br>字符输出 / 字符读取<br>系统关机<br>支持 nobios 直接操作 UART | 无 |
+| **tg-console** | 控制台 I/O<br>格式化输出（print! / println!）<br>日志系统（Log Level）<br>自旋锁保护的全局控制台 | 可定制 print! / println! 宏<br>log::Log 日志实现<br>Console trait 抽象底层输出 | 无 |
+| **tg-kernel-context** | 上下文（Context）<br>Trap 帧（Trap Frame）<br>寄存器保存与恢复<br>特权级切换<br>stvec / sepc / scause CSR<br>LocalContext（本地上下文）<br>ForeignContext（跨地址空间上下文）<br>异界传送门（MultislotPortal） | 用户/内核态切换上下文管理<br>LocalContext 结构<br>ForeignContext（含 satp）<br>MultislotPortal 跨地址空间执行 | 无 |
+| **tg-kernel-alloc** | 内核堆分配器<br>伙伴系统（Buddy Allocation）<br>动态内存管理<br>#[global_allocator] | 基于伙伴算法的 GlobalAlloc<br>堆初始化（init）<br>物理内存转移（transfer） | 无 |
+| **tg-kernel-vm** | 虚拟内存管理<br>页表（Page Table）<br>Sv39 分页（三级页表）<br>虚拟地址（VAddr）/ 物理地址（PAddr）<br>虚拟页号（VPN）/ 物理页号（PPN）<br>页表项（PTE）/ 页表标志位（VmFlags）<br>地址空间（AddressSpace）<br>PageManager trait<br>地址翻译（translate） | Sv39 页表管理<br>AddressSpace 地址空间抽象<br>虚实地址转换<br>页面映射（map / map_extern）<br>页表项操作 | 无 |
+| **tg-syscall** | 系统调用（System Call）<br>系统调用号（SyscallId）<br>系统调用分发（handle）<br>系统调用结果（Done / Unsupported）<br>Caller 抽象<br>IO / Process / Scheduling / Clock /<br>Signal / Thread / SyncMutex trait 接口 | 系统调用 ID 与参数定义<br>trait 接口供内核实现<br>init_io / init_process / init_scheduling /<br>init_clock / init_signal /<br>init_thread / init_sync_mutex<br>支持 kernel / user feature | tg-signal-defs |
+| **tg-task-manage** | 任务管理（Task Management）<br>调度（Scheduling）<br>进程管理器（PManager, proc feature）<br>双层管理器（PThreadManager, thread feature）<br>ProcId / ThreadId<br>就绪队列（Ready Queue）<br>Manage trait / Schedule trait<br>进程等待（wait / waitpid）<br>线程等待（waittid）<br>阻塞与唤醒（blocked / re_enque） | Manage 和 Schedule trait 抽象<br>proc feature：单层进程管理器（PManager）<br>thread feature：双层管理器（PThreadManager）<br>进程树 / 父子关系<br>线程阻塞 / 唤醒 | 无 |
+| **tg-easy-fs** | 文件系统（File System）<br>SuperBlock / Inode / 位图（Bitmap）<br>DiskInode（直接+间接索引）<br>块缓存（Block Cache）<br>BlockDevice trait<br>文件句柄（FileHandle）<br>打开标志（OpenFlags）<br>管道（Pipe）/ 环形缓冲区<br>用户缓冲区（UserBuffer）<br>FSManager trait | easy-fs 五层架构实现<br>文件创建 / 读写 / 目录操作<br>块缓存管理<br>管道环形缓冲区实现<br>FSManager trait 抽象 | 无 |
+| **tg-signal-defs** | 信号编号（SignalNo）<br>SIGKILL / SIGINT / SIGUSR1 等<br>信号动作（SignalAction）<br>信号集（SignalSet）<br>最大信号数（MAX_SIG） | 信号编号枚举定义<br>信号动作结构定义<br>信号集类型定义<br>为 tg-signal 和 tg-syscall 提供共用类型 | 无 |
+| **tg-signal** | 信号处理（Signal Handling）<br>Signal trait 接口<br>add_signal / handle_signals<br>get_action_ref / set_action<br>update_mask / sig_return / from_fork<br>SignalResult（Handled / ProcessKilled） | Signal trait 接口定义<br>信号添加 / 处理 / 动作设置<br>屏蔽字更新 / 信号返回<br>fork 继承 | tg-kernel-context<br>tg-signal-defs |
+| **tg-signal-impl** | SignalImpl 结构<br>已接收信号位图（received）<br>信号屏蔽字（mask）<br>信号处理中状态（handling）<br>信号动作表（actions）<br>信号处理函数调用<br>上下文保存与恢复 | Signal trait 的参考实现<br>信号接收位图管理<br>屏蔽字逻辑<br>处理状态和动作表 | tg-kernel-context<br>tg-signal |
+| **tg-sync** | 互斥锁（Mutex trait: lock / unlock）<br>阻塞互斥锁（MutexBlocking）<br>信号量（Semaphore: up / down）<br>条件变量（Condvar: signal / wait_with_mutex）<br>等待队列（VecDeque\<ThreadId\>）<br>UPIntrFreeCell | MutexBlocking 阻塞互斥锁<br>Semaphore 信号量<br>Condvar 条件变量<br>通过 ThreadId 与调度器交互 | tg-task-manage |
+| **tg-user** | 用户态程序（User-space App）<br>用户库（User Library）<br>系统调用封装（syscall wrapper）<br>用户堆分配器<br>用户态 print! / println! | 用户测试程序运行时库<br>系统调用封装<br>用户堆分配器<br>各章节测试用例（ch2~ch8） | tg-console<br>tg-syscall |
+| **tg-checker** | 测试验证<br>输出模式匹配<br>正则表达式（Regex）<br>测试用例判定 | rCore-Tutorial CLI 测试输出检查工具<br>验证内核输出匹配预期模式<br>支持 --ch N 和 --exercise 模式 | 无 |
+| **tg-linker** | 链接脚本（Linker Script）<br>内核内存布局（KernelLayout）<br>.text / .rodata / .data / .bss / .boot 段<br>入口点（boot0! 宏）<br>BSS 段清零 | 形成内核空间布局的链接脚本模板<br>用于 build.rs 工具构建 linker.ld<br>内核布局定位（KernelLayout::locate）<br>入口宏（boot0!）<br>段信息迭代 | 无 |
 ## License
 
 Licensed under GNU GENERAL PUBLIC LICENSE, Version 3.0.
diff --git a/blog-os-learning/os/ch3/src/main.rs b/blog-os-learning/os/ch3/src/main.rs
index 76c094c..1feaff5 100644
--- a/blog-os-learning/os/ch3/src/main.rs
+++ b/blog-os-learning/os/ch3/src/main.rs
@@ -102,9 +102,11 @@ extern "C" fn rust_main() -> ! {
     // 使用轮转调度算法（Round-Robin），依次执行各任务
     let mut remain = index_mod; // 剩余未完成的任务数
     let mut i = 0usize; // 当前任务索引
+    log::info!("Starting scheduler: {index_mod} tasks, remain={remain}");
     while remain > 0 {
         *CURRENT_TASK_IDX.lock() = i;
         let tcb = &mut TCBS.lock()[i];
+        log::debug!("scheduler: i={i}, remain={remain}, finish={}", tcb.finish);
         if !tcb.finish {
             loop {
                 // 【抢占式调度】设置时钟中断：12500 个时钟周期后触发
@@ -130,13 +132,16 @@ extern "C" fn rust_main() -> ! {
                     // ─── 系统调用：用户程序执行了 ecall 指令 ───
                     Trap::Exception(Exception::UserEnvCall) => {
                         use task::SchedulingEvent as Event;
-                        let result = tcb.handle_syscall();
-                        match result.event {
+                        match tcb.handle_syscall() {
                             // 普通系统调用（如 write）：处理完成后继续运行当前任务
                             Event::None => continue,
                             // exit 系统调用：任务主动退出
                             Event::Exit(code) => {
                                 log::info!("app{i} exit with code {code}");
+                                log::debug!(
+                                    "app{i} will set finish=true, remain going from {remain} to {}",
+                                    remain - 1
+                                );
                                 true
                             }
                             // yield 系统调用：任务主动让出 CPU
@@ -165,11 +170,17 @@ extern "C" fn rust_main() -> ! {
 
                 // 如果任务结束（退出或被杀死），标记为已完成
                 if finish {
+                    log::debug!(
+                        "setting finish=true for app{i}, remain {remain} -> {}",
+                        remain - 1
+                    );
                     tcb.finish = true;
                     remain -= 1;
                 }
                 break;
             }
+        } else {
+            log::debug!("app{i} already finished, skipping");
         }
         // 轮转到下一个任务（循环取模）
         i = (i + 1) % index_mod;
@@ -192,7 +203,7 @@ fn panic(info: &core::panic::PanicInfo) -> ! {
 
 /// 各依赖库所需接口的具体实现
 mod impls {
-    use crate::{CURRENT_TASK_IDX, TCBS};
+    // CURRENT_TASK_IDX and TCBS are no longer needed here
     use tg_console::log;
     use tg_syscall::*;
 
@@ -303,12 +314,10 @@ mod impls {
                     0
                 }
                 2 => {
-                    // 查询系统调用计数
-                    let idx = *CURRENT_TASK_IDX.lock();
-                    log::trace!("trace count: idx={}, syscall_id={}", idx, id);
-                    let count = TCBS.lock()[idx].syscall_counts[id] as isize;
-                    log::trace!("trace count result = {}", count);
-                    count
+                    // 查询系统调用计数 - 注意：此功能已在 task.rs 的 handle_syscall 中处理
+                    // 此处返回 -1 表示未实现
+                    log::trace!("trace count: this should be handled in task.rs");
+                    -1
                 }
                 _ => -1,
             }
diff --git a/blog-os-learning/os/ch3/src/task.rs b/blog-os-learning/os/ch3/src/task.rs
index 6207b0c..c7c2044 100644
--- a/blog-os-learning/os/ch3/src/task.rs
+++ b/blog-os-learning/os/ch3/src/task.rs
@@ -8,6 +8,12 @@
 //! 第二章的批处理系统中，用户上下文直接在 `rust_main` 的局部变量中管理。
 //! 本章将其封装到 `TaskControlBlock` 中，每个任务拥有独立的 TCB，
 //! 包含用户上下文、完成状态和独立的用户栈，支持多任务并发。
+//!
+//! 教程阅读建议：
+//!
+//! - 先看 `TaskControlBlock` 字段：理解“上下文 + 栈 + 状态位”最小任务模型；
+//! - 再看 `handle_syscall`：理解系统调用结果如何映射成调度事件；
+//! - 最后对照 `ch3/src/main.rs`：把“事件生成”和“事件消费”串成闭环。
 
 use tg_kernel_context::LocalContext;
 use tg_syscall::{Caller, SyscallId};
@@ -18,6 +24,7 @@ use tg_syscall::{Caller, SyscallId};
 /// - `ctx`：用户态上下文（所有通用寄存器 + 控制寄存器），用于任务切换时保存/恢复状态
 /// - `finish`：任务是否已完成（退出或被杀死）
 /// - `stack`：用户栈空间（8 KiB），每个任务有独立的栈
+/// - `syscall_counts`：系统调用计数数组，用于 trace 功能
 pub struct TaskControlBlock {
     /// 用户态上下文：保存 Trap 时的所有寄存器状态
     ctx: LocalContext,
@@ -26,8 +33,8 @@ pub struct TaskControlBlock {
     /// 用户栈：8 KiB（1024 个 usize = 1024 × 8 = 8192 字节）
     /// 每个任务拥有独立的栈空间，避免栈溢出影响其他任务
     stack: [usize; 1024],
-    // 统计对系统调用的调用次数（可选）
-    pub syscall_counts: [usize; 1024],
+    /// 系统调用计数数组，索引为系统调用号，值为调用次数
+    pub syscall_counts: [usize; 512],
 }
 
 /// 调度事件
@@ -45,18 +52,13 @@ pub enum SchedulingEvent {
     UnsupportedSyscall(SyscallId),
 }
 
-/// handle_syscall 的返回值，包含调度事件和系统调用 ID
-pub struct SyscallResult {
-    pub event: SchedulingEvent,
-}
-
 impl TaskControlBlock {
     /// 零值常量：用于数组初始化
     pub const ZERO: Self = Self {
         ctx: LocalContext::empty(),
         finish: false,
         stack: [0; 1024],
-        syscall_counts: [0; 1024],
+        syscall_counts: [0; 512],
     };
 
     /// 初始化一个任务
@@ -64,9 +66,11 @@ impl TaskControlBlock {
     /// - 清零用户栈
     /// - 创建用户态上下文，设置入口地址和 `sstatus.SPP = User`
     /// - 将栈指针设置为用户栈的栈顶（高地址端）
+    /// - 清零系统调用计数
     pub fn init(&mut self, entry: usize) {
         self.stack.fill(0);
         self.finish = false;
+        self.syscall_counts.fill(0);
         self.ctx = LocalContext::user(entry);
         // 栈从高地址向低地址增长，所以 sp 指向栈顶（数组末尾之后的地址）
         *self.ctx.sp_mut() = self.stack.as_ptr() as usize + core::mem::size_of_val(&self.stack);
@@ -81,12 +85,12 @@ impl TaskControlBlock {
         unsafe { self.ctx.execute() };
     }
 
-    /// 处理系统调用，返回调度事件和系统调用ID
+    /// 处理系统调用，返回调度事件
     ///
     /// 从用户上下文中提取系统调用 ID（a7 寄存器）和参数（a0-a5 寄存器），
     /// 分发到对应的处理函数，并将返回值写回 a0 寄存器。
-    /// 在内部统计系统调用次数。
-    pub fn handle_syscall(&mut self) -> SyscallResult {
+    /// 同时统计系统调用次数。
+    pub fn handle_syscall(&mut self) -> SchedulingEvent {
         use tg_syscall::{SyscallId as Id, SyscallResult as Ret};
         use SchedulingEvent as Event;
 
@@ -94,8 +98,10 @@ impl TaskControlBlock {
         let id: SyscallId = self.ctx.a(7).into();
         let syscall_id = id.0 as usize;
 
-        // 统计系统调用次数（在调用 tg_syscall::handle 之前！）
-        self.syscall_counts[syscall_id] += 1;
+        // 统计系统调用次数
+        if syscall_id < self.syscall_counts.len() {
+            self.syscall_counts[syscall_id] += 1;
+        }
 
         // a0-a5 寄存器存放系统调用参数
         let args = [
@@ -106,7 +112,33 @@ impl TaskControlBlock {
             self.ctx.a(4),
             self.ctx.a(5),
         ];
-        let event = match tg_syscall::handle(Caller { entity: 0, flow: 0 }, id, args) {
+
+        // 处理 trace 系统调用（ID 410）
+        if let Id::TRACE = id {
+            let trace_request = args[0];
+            let trace_id = args[1];
+            let trace_data = args[2];
+            let ret = match trace_request {
+                0 => unsafe { *(trace_id as *const u8) as isize },
+                1 => {
+                    unsafe { *(trace_id as *mut u8) = trace_data as u8 };
+                    0
+                }
+                2 => {
+                    if trace_id < self.syscall_counts.len() {
+                        self.syscall_counts[trace_id] as isize
+                    } else {
+                        -1
+                    }
+                }
+                _ => -1,
+            };
+            *self.ctx.a_mut(0) = ret as _;
+            self.ctx.move_next();
+            return Event::None;
+        }
+
+        match tg_syscall::handle(Caller { entity: 0, flow: 0 }, id, args) {
             Ret::Done(ret) => match id {
                 // exit 系统调用：返回退出事件
                 Id::EXIT => Event::Exit(self.ctx.a(0)),
@@ -125,8 +157,6 @@ impl TaskControlBlock {
             },
             // 不支持的系统调用
             Ret::Unsupported(_) => Event::UnsupportedSyscall(id),
-        };
-
-        SyscallResult { event }
+        }
     }
 }
**记录原因**: 包含保留关键词: Rust


---

### 对话 inputsession-ses_3a56.md_54 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 现在我可以总结工作内容了。让我查看一下 day4.md 来确保我理解正确：

50: // 新增字段
51: pub syscall_counts: [usize; 512]
52: 
53: // init 中清零计数数组
54: self.syscall_counts.fill(0);
55: 
56: // handle_syscall 中统计系统调用
57: let syscall_id = id.0 as usize;
58: if syscall_id < self.syscall_counts.len() {
59:     self.syscall_counts[syscall_id] += 1;
60: }
61: 
62: // 在调用 tg_syscall::handle 之前处理 trace
63: if let Id::TRACE = id {
64:     // 直接访问 self.syscall_counts（已持有锁）
65:     let ret = match trace_request {
66:         0 => unsafe { *(trace_id as *const u8) as isize },
67:         1 => { unsafe { *(trace_id as *mut u8) = trace_data as u8 }; 0 }
68:         2 => if trace_id < self.syscall_counts.len() { 
69:             self.syscall_counts[trace_id] as isize 
70:         } else { -1 },
71:         _ => -1,
72:     };
73:     *self.ctx.a_mut(0) = ret as _;
74:     self.ctx.move_next();
75:     return Event::None;
76: }
**记录原因**: 包含保留关键词: match


---

### 对话 inputsession-ses_3a56.md_55 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 现在我可以总结工作内容并生成 commit message 了。

## 工作总结

### 主要工作

1. **修复 ch3 练习测试死锁问题**
   - 问题：练习测试运行时卡死
   - 根因：trace 系统调用的功能 2 在 `SyscallContext::trace` 中尝试再次获取 `TCBS.lock()`，导致死锁
   - 解决：将 trace 系统调用处理移到 `handle_syscall` 内部（在持有锁的上下文中）

2. **实现 sys_trace 系统调用**
   - 功能 0：读取用户内存
   - 功能 1：写入用户内存  
   - 功能 2：查询系统调用计数

3. **代码优化**
   - 添加调度日志便于调试
   - 修复 `syscall_counts` 数组大小（1024 → 512）

4. **文档更新**
   - 添加源码阅读导航索引
   - 添加 DoD 验收标准
   - 添加概念-源码-测试三联表
   - 添加组件分析表（tg-ch1~ch8）
   - 添加工作日志 day4.md
**记录原因**: 包含保留关键词: 系统调用


---

### 对话 inputsession-ses_3a56.md_57 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 用户想让我看更改区。让我查看具体的更改内容。

 
+<a id="source-nav"></a>
+
+## 源码阅读导航索引
+
+[返回根文档导航总表](../README.md#chapters-source-nav-map)
+
+本章建议按“任务模型 -> 调度循环 -> 时钟中断/系统调用”顺序阅读。
+
+| 阅读顺序 | 文件 | 重点问题 |
+|---|---|---|
+| 1 | `src/task.rs` | `TaskControlBlock` 如何封装上下文、栈和任务状态？ |
+| 2 | `src/main.rs` 的主循环 | 轮转调度如何在多任务之间切换？ |
+| 3 | 时钟中断分支 | 抢占式调度中，时间片到期后发生了什么？ |
+| 4 | `yield` 与 syscall 分支 | 协作式让出与普通 syscall 返回路径有何区别？ |
+
+配套建议：结合 `tg-sbi::set_timer` 与 `clock_gettime` 实现，串起“硬件时钟 -> 内核调度 -> 用户可见时间”的链路。
+
+## DoD 验收标准（本章完成判据）
+
+- [ ] 能运行 `cargo run` 并说明抢占式调度（时钟中断）发生的证据
+- [ ] 能运行 `cargo run --features coop` 并说明协作式调度与抢占式差异
+- [ ] 能解释 `TaskControlBlock` 中“上下文/栈/完成状态”的作用
+- [ ] 能从 Trap 分支区分 `SupervisorTimer` 与 `UserEnvCall` 两类事件
+- [ ] 能完成 `./test.sh base`（以及练习时 `./test.sh exercise`）
+
+## 概念-源码-测试三联表
+
+| 核心概念 | 源码入口 | 自测方式（命令/现象） |
+|---|---|---|
+| 任务控制块（TCB） | `ch3/src/task.rs` | 能说清 `init/execute/handle_syscall` 的职责 |
+| 抢占式调度 | `ch3/src/main.rs` 的时钟中断分支 | 日志出现 timeout/轮转切换行为 |
+| 协作式调度 | `ch3/src/main.rs` 的 `Event::Yield` 分支 | `--features coop` 下由用户主动让出 CPU |
+| 时间系统调用 | `ch3/src/main.rs` 的 `Clock` 实现 | 用户态 `clock_gettime` 返回时间单调递增 |
+
+遇到构建/运行异常可先查看根文档的“高频错误速查表”。
+
 ## 一、环境准备
 
 ### 1.1 安装 Rust 工具链
@@ -98,8 +134,8 @@ cd tg-ch3
 **方式二：获取所有实验**
 
 
 ## 二、编译与运行
@@ -611,6 +647,42 @@ cargo run --features exercise
 - [RISC-V Privileged Specification](https://riscv.org/specifications/privileged-isa/)
 - [RISC-V Reader 中文版](http://riscvbook.com/chinese/RISC-V-Reader-Chinese-v2p1.pdf)
 
+---
+
+## 附录：rCore-Tutorial 组件分析表
+
+### 表 1：tg-ch1 ~ tg-ch8 操作系统内核总体情况描述表
+
+| 操作系统内核 | 所涉及核心知识点 | 主要完成功能 | 所依赖的组件 |
+|:-----|:------------|:---------|:---------------|
+| **tg-ch1** | 应用程序执行环境<br>裸机编程（Bare-metal）<br>SBI（Supervisor Binary Interface）<br>RISC-V 特权级（M/S-mode）<br>链接脚本（Linker Script）<br>内存布局（Memory Layout）<br>Panic 处理 | 最小 S-mode 裸机程序<br>QEMU 直接启动（无 OpenSBI）<br>打印 "Hello, world!" 并关机<br>演示最基本的 OS 执行环境 | tg-sbi |
+| **tg-ch2** | 批处理系统（Batch Processing）<br>特权级切换（U-mode ↔ S-mode）<br>Trap 处理（ecall / 异常）<br>上下文保存与恢复<br>系统调用（write / exit）<br>用户态 / 内核态<br>`sret` 返回指令 | 批处理操作系统<br>顺序加载运行多个用户程序<br>特权级切换和 Trap 处理框架<br>实现 write / exit 系统调用 | tg-sbi<br>tg-linker<br>tg-console<br>tg-kernel-context<br>tg-syscall |
+| **tg-ch4** | 虚拟内存（Virtual Memory）<br>Sv39 三级页表（Page Table）<br>地址空间隔离（Address Space）<br>页表项（PTE）与标志位<br>地址转换（VA → PA）<br>异界传送门（MultislotPortal）<br>ELF 加载与解析<br>堆管理（sbrk）<br>恒等映射（Identity Mapping）<br>内存保护（Memory Protection）<br>satp CSR | 引入 Sv39 虚拟内存<br>每个用户进程独立地址空间<br>跨地址空间上下文切换<br>进程隔离和内存保护 | tg-sbi<br>tg-linker<br>tg-console<br>tg-kernel-context<br>tg-kernel-alloc<br>tg-kernel-vm<br>tg-syscall |
+| **tg-ch6** | 文件系统（File System）<br>easy-fs 五层架构<br>SuperBlock / Inode / 位图<br>DiskInode（直接+间接索引）<br>目录项（DirEntry）<br>文件描述符表（fd_table）<br>文件句柄（FileHandle）<br>VirtIO 块设备驱动<br>MMIO（Memory-Mapped I/O）<br>块缓存（Block Cache）<br>硬链接（Hard Link）<br>open / close / read / write 系统调用 | 引入文件系统与 I/O<br>用户程序存储在磁盘镜像（fs.img）<br>VirtIO 块设备驱动<br>easy-fs 文件系统实现<br>文件打开 / 关闭 / 读写 | tg-sbi<br>tg-linker<br>tg-console<br>tg-kernel-context<br>tg-kernel-alloc<br>tg-kernel-vm<br>tg-syscall<br>tg-task-manage<br>tg-easy-fs |
+| **tg-ch7** | 进程间通信（IPC）<br>管道（Pipe）<br>环形缓冲区（Ring Buffer）<br>统一文件描述符（Fd 枚举）<br>信号（Signal）<br>信号集（SignalSet）<br>信号屏蔽字（Signal Mask）<br>信号处理函数（Signal Handler）<br>kill / sigaction / sigprocmask / sigreturn<br>命令行参数（argc / argv）<br>I/O 重定向（dup） | 进程间通信-管道 <br>异步事件通知（信号）<br>统一文件描述符抽象<br>信号发送 / 注册 / 屏蔽 / 返回 | tg-sbi<br>tg-linker<br>tg-console<br>tg-kernel-context<br>tg-kernel-alloc<br>tg-kernel-vm<br>tg-syscall<br>tg-task-manage<br>tg-easy-fs<br>tg-signal<br>tg-signal-impl |
+| **tg-ch8** | 同步互斥（Sync&Mutex）<br>线程（Thread）/ 线程标识符（TID）<br>进程-线程分离<br>竞态条件（Race Condition）<br>临界区（Critical Section）<br>互斥（Mutual Exclusion）<br>互斥锁（Mutex：自旋锁 vs 阻塞锁）<br>信号量（Semaphore：P/V 操作）<br>条件变量（Condvar）<br>管程（Monitor：Mesa 语义）<br>线程阻塞与唤醒（wait queue）<br>死锁（Deadlock）/ 死锁四条件<br>银行家算法（Banker's Algorithm）<br>双层管理器（PThreadManager） | 进程-线程分离<br>同一进程内多线程并发<br>互斥锁（MutexBlocking）<br>信号量（Semaphore）<br>条件变量（Condvar）<br>线程阻塞与唤醒机制<br>死锁检测（练习） | tg-sbi<br>tg-linker<br>tg-console<br>tg-kernel-context<br>tg-kernel-alloc<br>tg-kernel-vm<br>tg-syscall<br>tg-task-manage<br>tg-easy-fs<br>tg-signal<br>tg-signal-impl<br>tg-sync |
+
+### 表 2：tg-ch1 ~ tg-ch8 操作系统内核所依赖组件总体情况描述表
+
+| 功能组件 | 所涉及核心知识点 | 主要完成功能 | 所依赖的组件 |
+|:-----|:------------|:---------|:----------------------|
+| **tg-sbi** | SBI（Supervisor Binary Interface）<br>console_putchar / console_getchar<br>系统关机（shutdown）<br>RISC-V 特权级（M/S-mode）<br>ecall 指令 | S→M 模式的 SBI 调用封装<br>字符输出 / 字符读取<br>系统关机<br>支持 nobios 直接操作 UART | 无 |
+| **tg-console** | 控制台 I/O<br>格式化输出（print! / println!）<br>日志系统（Log Level）<br>自旋锁保护的全局控制台 | 可定制 print! / println! 宏<br>log::Log 日志实现<br>Console trait 抽象底层输出 | 无 |
+| **tg-kernel-context** | 上下文（Context）<br>Trap 帧（Trap Frame）<br>寄存器保存与恢复<br>特权级切换<br>stvec / sepc / scause CSR<br>LocalContext（本地上下文）<br>ForeignContext（跨地址空间上下文）<br>异界传送门（MultislotPortal） | 用户/内核态切换上下文管理<br>LocalContext 结构<br>ForeignContext（含 satp）<br>MultislotPortal 跨地址空间执行 | 无 |
+| **tg-kernel-alloc** | 内核堆分配器<br>伙伴系统（Buddy Allocation）<br>动态内存管理<br>#[global_allocator] | 基于伙伴算法的 GlobalAlloc<br>堆初始化（init）<br>物理内存转移（transfer） | 无 |
+| **tg-kernel-vm** | 虚拟内存管理<br>页表（Page Table）<br>Sv39 分页（三级页表）<br>虚拟地址（VAddr）/ 物理地址（PAddr）<br>虚拟页号（VPN）/ 物理页号（PPN）<br>页表项（PTE）/ 页表标志位（VmFlags）<br>地址空间（AddressSpace）<br>PageManager trait<br>地址翻译（translate） | Sv39 页表管理<br>AddressSpace 地址空间抽象<br>虚实地址转换<br>页面映射（map / map_extern）<br>页表项操作 | 无 |
+| **tg-syscall** | 系统调用（System Call）<br>系统调用号（SyscallId）<br>系统调用分发（handle）<br>系统调用结果（Done / Unsupported）<br>Caller 抽象<br>IO / Process / Scheduling / Clock /<br>Signal / Thread / SyncMutex trait 接口 | 系统调用 ID 与参数定义<br>trait 接口供内核实现<br>init_io / init_process / init_scheduling /<br>init_clock / init_signal /<br>init_thread / init_sync_mutex<br>支持 kernel / user feature | tg-signal-defs |
+| **tg-task-manage** | 任务管理（Task Management）<br>调度（Scheduling）<br>进程管理器（PManager, proc feature）<br>双层管理器（PThreadManager, thread feature）<br>ProcId / ThreadId<br>就绪队列（Ready Queue）<br>Manage trait / Schedule trait<br>进程等待（wait / waitpid）<br>线程等待（waittid）<br>阻塞与唤醒（blocked / re_enque） | Manage 和 Schedule trait 抽象<br>proc feature：单层进程管理器（PManager）<br>thread feature：双层管理器（PThreadManager）<br>进程树 / 父子关系<br>线程阻塞 / 唤醒 | 无 |
+| **tg-easy-fs** | 文件系统（File System）<br>SuperBlock / Inode / 位图（Bitmap）<br>DiskInode（直接+间接索引）<br>块缓存（Block Cache）<br>BlockDevice trait<br>文件句柄（FileHandle）<br>打开标志（OpenFlags）<br>管道（Pipe）/ 环形缓冲区<br>用户缓冲区（UserBuffer）<br>FSManager trait | easy-fs 五层架构实现<br>文件创建 / 读写 / 目录操作<br>块缓存管理<br>管道环形缓冲区实现<br>FSManager trait 抽象 | 无 |
+| **tg-signal-defs** | 信号编号（SignalNo）<br>SIGKILL / SIGINT / SIGUSR1 等<br>信号动作（SignalAction）<br>信号集（SignalSet）<br>最大信号数（MAX_SIG） | 信号编号枚举定义<br>信号动作结构定义<br>信号集类型定义<br>为 tg-signal 和 tg-syscall 提供共用类型 | 无 |
+| **tg-signal** | 信号处理（Signal Handling）<br>Signal trait 接口<br>add_signal / handle_signals<br>get_action_ref / set_action<br>update_mask / sig_return / from_fork<br>SignalResult（Handled / ProcessKilled） | Signal trait 接口定义<br>信号添加 / 处理 / 动作设置<br>屏蔽字更新 / 信号返回<br>fork 继承 | tg-kernel-context<br>tg-signal-defs |
+| **tg-signal-impl** | SignalImpl 结构<br>已接收信号位图（received）<br>信号屏蔽字（mask）<br>信号处理中状态（handling）<br>信号动作表（actions）<br>信号处理函数调用<br>上下文保存与恢复 | Signal trait 的参考实现<br>信号接收位图管理<br>屏蔽字逻辑<br>处理状态和动作表 | tg-kernel-context<br>tg-signal |
+| **tg-sync** | 互斥锁（Mutex trait: lock / unlock）<br>阻塞互斥锁（MutexBlocking）<br>信号量（Semaphore: up / down）<br>条件变量（Condvar: signal / wait_with_mutex）<br>等待队列（VecDeque\<ThreadId\>）<br>UPIntrFreeCell | MutexBlocking 阻塞互斥锁<br>Semaphore 信号量<br>Condvar 条件变量<br>通过 ThreadId 与调度器交互 | tg-task-manage |
+| **tg-user** | 用户态程序（User-space App）<br>用户库（User Library）<br>系统调用封装（syscall wrapper）<br>用户堆分配器<br>用户态 print! / println! | 用户测试程序运行时库<br>系统调用封装<br>用户堆分配器<br>各章节测试用例（ch2~ch8） | tg-console<br>tg-syscall |
+| **tg-checker** | 测试验证<br>输出模式匹配<br>正则表达式（Regex）<br>测试用例判定 | rCore-Tutorial CLI 测试输出检查工具<br>验证内核输出匹配预期模式<br>支持 --ch N 和 --exercise 模式 | 无 |
+| **tg-linker** | 链接脚本（Linker Script）<br>内核内存布局（KernelLayout）<br>.text / .rodata / .data / .bss / .boot 段<br>入口点（boot0! 宏）<br>BSS 段清零 | 形成内核空间布局的链接脚本模板<br>用于 build.rs 工具构建 linker.ld<br>内核布局定位（KernelLayout::locate）<br>入口宏（boot0!）<br>段信息迭代 | 无 |
 ## License
 
 Licensed under GNU GENERAL PUBLIC LICENSE, Version 3.0.
diff --git a/blog-os-learning/os/ch3/src/main.rs b/blog-os-learning/os/ch3/src/main.rs
index 76c094c..1feaff5 100644
--- a/blog-os-learning/os/ch3/src/main.rs
+++ b/blog-os-learning/os/ch3/src/main.rs
@@ -102,9 +102,11 @@ extern "C" fn rust_main() -> ! {
     // 使用轮转调度算法（Round-Robin），依次执行各任务
     let mut remain = index_mod; // 剩余未完成的任务数
     let mut i = 0usize; // 当前任务索引
+    log::info!("Starting scheduler: {index_mod} tasks, remain={remain}");
     while remain > 0 {
         *CURRENT_TASK_IDX.lock() = i;
         let tcb = &mut TCBS.lock()[i];
+        log::debug!("scheduler: i={i}, remain={remain}, finish={}", tcb.finish);
         if !tcb.finish {
             loop {
                 // 【抢占式调度】设置时钟中断：12500 个时钟周期后触发
@@ -130,13 +132,16 @@ extern "C" fn rust_main() -> ! {
                     // ─── 系统调用：用户程序执行了 ecall 指令 ───
                     Trap::Exception(Exception::UserEnvCall) => {
                         use task::SchedulingEvent as Event;
-                        let result = tcb.handle_syscall();
-                        match result.event {
+                        match tcb.handle_syscall() {
                             // 普通系统调用（如 write）：处理完成后继续运行当前任务
                             Event::None => continue,
                             // exit 系统调用：任务主动退出
                             Event::Exit(code) => {
                                 log::info!("app{i} exit with code {code}");
+                                log::debug!(
+                                    "app{i} will set finish=true, remain going from {remain} to {}",
+                                    remain - 1
+                                );
                                 true
                             }
                             // yield 系统调用：任务主动让出 CPU
@@ -165,11 +170,17 @@ extern "C" fn rust_main() -> ! {
 
                 // 如果任务结束（退出或被杀死），标记为已完成
                 if finish {
+                    log::debug!(
+                        "setting finish=true for app{i}, remain {remain} -> {}",
+                        remain - 1
+                    );
                     tcb.finish = true;
                     remain -= 1;
                 }
                 break;
             }
+        } else {
+            log::debug!("app{i} already finished, skipping");
         }
         // 轮转到下一个任务（循环取模）
         i = (i + 1) % index_mod;
@@ -192,7 +203,7 @@ fn panic(info: &core::panic::PanicInfo) -> ! {
 
 /// 各依赖库所需接口的具体实现
 mod impls {
-    use crate::{CURRENT_TASK_IDX, TCBS};
+    // CURRENT_TASK_IDX and TCBS are no longer needed here
     use tg_console::log;
     use tg_syscall::*;
 
@@ -303,12 +314,10 @@ mod impls {
                     0
                 }
                 2 => {
-                    // 查询系统调用计数
-                    let idx = *CURRENT_TASK_IDX.lock();
-                    log::trace!("trace count: idx={}, syscall_id={}", idx, id);
-                    let count = TCBS.lock()[idx].syscall_counts[id] as isize;
-                    log::trace!("trace count result = {}", count);
-                    count
+                    // 查询系统调用计数 - 注意：此功能已在 task.rs 的 handle_syscall 中处理
+                    // 此处返回 -1 表示未实现
+                    log::trace!("trace count: this should be handled in task.rs");
+                    -1
                 }
                 _ => -1,
             }
diff --git a/blog-os-learning/os/ch3/src/task.rs b/blog-os-learning/os/ch3/src/task.rs
index 6207b0c..c7c2044 100644
--- a/blog-os-learning/os/ch3/src/task.rs
+++ b/blog-os-learning/os/ch3/src/task.rs
@@ -8,6 +8,12 @@
 //! 第二章的批处理系统中，用户上下文直接在 `rust_main` 的局部变量中管理。
 //! 本章将其封装到 `TaskControlBlock` 中，每个任务拥有独立的 TCB，
 //! 包含用户上下文、完成状态和独立的用户栈，支持多任务并发。
+//!
+//! 教程阅读建议：
+//!
+//! - 先看 `TaskControlBlock` 字段：理解“上下文 + 栈 + 状态位”最小任务模型；
+//! - 再看 `handle_syscall`：理解系统调用结果如何映射成调度事件；
+//! - 最后对照 `ch3/src/main.rs`：把“事件生成”和“事件消费”串成闭环。
 
 use tg_kernel_context::LocalContext;
 use tg_syscall::{Caller, SyscallId};
@@ -18,6 +24,7 @@ use tg_syscall::{Caller, SyscallId};
 /// - `ctx`：用户态上下文（所有通用寄存器 + 控制寄存器），用于任务切换时保存/恢复状态
 /// - `finish`：任务是否已完成（退出或被杀死）
 /// - `stack`：用户栈空间（8 KiB），每个任务有独立的栈
+/// - `syscall_counts`：系统调用计数数组，用于 trace 功能
 pub struct TaskControlBlock {
     /// 用户态上下文：保存 Trap 时的所有寄存器状态
     ctx: LocalContext,
@@ -26,8 +33,8 @@ pub struct TaskControlBlock {
     /// 用户栈：8 KiB（1024 个 usize = 1024 × 8 = 8192 字节）
     /// 每个任务拥有独立的栈空间，避免栈溢出影响其他任务
     stack: [usize; 1024],
-    // 统计对系统调用的调用次数（可选）
-    pub syscall_counts: [usize; 1024],
+    /// 系统调用计数数组，索引为系统调用号，值为调用次数
+    pub syscall_counts: [usize; 512],
 }
 
 /// 调度事件
@@ -45,18 +52,13 @@ pub enum SchedulingEvent {
     UnsupportedSyscall(SyscallId),
 }
 
-/// handle_syscall 的返回值，包含调度事件和系统调用 ID
-pub struct SyscallResult {
-    pub event: SchedulingEvent,
-}
-
 impl TaskControlBlock {
     /// 零值常量：用于数组初始化
     pub const ZERO: Self = Self {
         ctx: LocalContext::empty(),
         finish: false,
         stack: [0; 1024],
-        syscall_counts: [0; 1024],
+        syscall_counts: [0; 512],
     };
 
     /// 初始化一个任务
@@ -64,9 +66,11 @@ impl TaskControlBlock {
     /// - 清零用户栈
     /// - 创建用户态上下文，设置入口地址和 `sstatus.SPP = User`
     /// - 将栈指针设置为用户栈的栈顶（高地址端）
+    /// - 清零系统调用计数
     pub fn init(&mut self, entry: usize) {
         self.stack.fill(0);
         self.finish = false;
+        self.syscall_counts.fill(0);
         self.ctx = LocalContext::user(entry);
         // 栈从高地址向低地址增长，所以 sp 指向栈顶（数组末尾之后的地址）
         *self.ctx.sp_mut() = self.stack.as_ptr() as usize + core::mem::size_of_val(&self.stack);
@@ -81,12 +85,12 @@ impl TaskControlBlock {
         unsafe { self.ctx.execute() };
     }
 
-    /// 处理系统调用，返回调度事件和系统调用ID
+    /// 处理系统调用，返回调度事件
     ///
     /// 从用户上下文中提取系统调用 ID（a7 寄存器）和参数（a0-a5 寄存器），
     /// 分发到对应的处理函数，并将返回值写回 a0 寄存器。
-    /// 在内部统计系统调用次数。
-    pub fn handle_syscall(&mut self) -> SyscallResult {
+    /// 同时统计系统调用次数。
+    pub fn handle_syscall(&mut self) -> SchedulingEvent {
         use tg_syscall::{SyscallId as Id, SyscallResult as Ret};
         use SchedulingEvent as Event;
 
@@ -94,8 +98,10 @@ impl TaskControlBlock {
         let id: SyscallId = self.ctx.a(7).into();
         let syscall_id = id.0 as usize;
 
-        // 统计系统调用次数（在调用 tg_syscall::handle 之前！）
-        self.syscall_counts[syscall_id] += 1;
+        // 统计系统调用次数
+        if syscall_id < self.syscall_counts.len() {
+            self.syscall_counts[syscall_id] += 1;
+        }
 
         // a0-a5 寄存器存放系统调用参数
         let args = [
@@ -106,7 +112,33 @@ impl TaskControlBlock {
             self.ctx.a(4),
             self.ctx.a(5),
         ];
-        let event = match tg_syscall::handle(Caller { entity: 0, flow: 0 }, id, args) {
+
+        // 处理 trace 系统调用（ID 410）
+        if let Id::TRACE = id {
+            let trace_request = args[0];
+            let trace_id = args[1];
+            let trace_data = args[2];
+            let ret = match trace_request {
+                0 => unsafe { *(trace_id as *const u8) as isize },
+                1 => {
+                    unsafe { *(trace_id as *mut u8) = trace_data as u8 };
+                    0
+                }
+                2 => {
+                    if trace_id < self.syscall_counts.len() {
+                        self.syscall_counts[trace_id] as isize
+                    } else {
+                        -1
+                    }
+                }
+                _ => -1,
+            };
+            *self.ctx.a_mut(0) = ret as _;
+            self.ctx.move_next();
+            return Event::None;
+        }
+
+        match tg_syscall::handle(Caller { entity: 0, flow: 0 }, id, args) {
             Ret::Done(ret) => match id {
                 // exit 系统调用：返回退出事件
                 Id::EXIT => Event::Exit(self.ctx.a(0)),
@@ -125,8 +157,6 @@ impl TaskControlBlock {
             },
             // 不支持的系统调用
             Ret::Unsupported(_) => Event::UnsupportedSyscall(id),
-        };
-
-        SyscallResult { event }
+        }
     }
 }
**记录原因**: 包含保留关键词: Rust


---

### 对话 inputsession-ses_3a56.md_58 - [Ch3 测试未通过原因分析]
**时间**: 2026-02-14 14:51:33
**用户**: Ch3 测试未通过原因分析
**助手**: 这是完整的更改区内容。让我总结一下：

1. **Cargo.toml** - 更新版本和仓库地址
2. **README.md** - 添加了源码导航、DoD验收标准、组件分析表等
3. **src/main.rs** - 修复死锁问题，简化trace实现
4. **src/task.rs** - 实现sys_trace系统调用，修复syscall_counts数组大小

还有一个未跟踪的 work/week1/day4.md 文件。

让我总结给用户。

## 更改区总结

### 已修改文件（4个）

| 文件 | 主要改动 |
|------|---------|
| `os/ch3/Cargo.toml` | 更新版本 0.3.1→0.4.2，仓库地址更新 |
| `os/ch3/README.md` | 添加源码导航、DoD验收标准、组件分析表 |
| `os/ch3/src/main.rs` | 修复死锁，简化trace实现，添加调度日志 |
| `os/ch3/src/task.rs` | 实现sys_trace，修复syscall_counts大小(1024→512) |

### 未跟踪文件（2个）

- `work/week1/day4.md` - 工作日志
- `img/work/img.png` - 已暂存
**记录原因**: 包含保留关键词: 系统调用



